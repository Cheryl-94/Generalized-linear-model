setwd("~/Downloads/UVic/STAT568/glm project")
###======== STAT568 (17-18 sem2) Group Project ===========####
#                                                            #
#        Predictive Models for Credit Card Default           #
#                                                            #
####======================================================####
# Group members                                 
#
# LIU, Ben       V00863757      
# LIU, Meixin    V00812082    
# XIE, Peijie    V00887527          
#
####==========================================================
# Notice:
# The plots generated by the code will be automatically saved into the file
# "STAT568_plots" in the working directory. 
####==========================================================

#############
#           # 
# Settings  #
#           #
#############

save.to.dir <- file.path(getwd(),'STAT568_plots')
dir.create(save.to.dir, showWarnings = F)

##############################
#                            #           
# Install and load packages  #
#                            #            
##############################

if(!require('MLmetrics')) install.packages('MLmetrics')
if(!require('ggplot2')) install.packages('ggplot2')
if(!require('plyr')) install.packages('plyr')
if(!require('reshape')) install.packages('reshape')
if(!require('pROC')) install.packages('pROC')
if(!require('dotwhisker')) install.packages('dotwhisker')
if(!require('broom')) install.packages('broom')
if(!require('dplyr')) install.packages('dplyr')
if(!require('MASS')) install.packages('MASS')
if(!require('glmnet')) install.packages('glmnet')
if(!require('class')) install.packages('class')
if(!require('caret')) install.packages('caret')
if(!require('ROCR')) install.packages('ROCR')
if(!require('tree')) install.packages('tree')
if(!require('rpart')) install.packages('rpart')
if(!require('rpart.plot')) install.packages('rpart.plot')
if(!require('randomForest')) install.packages('randomForest')
if(!require('klaR')) install.packages('klaR')

library(MLmetrics)
library(ggplot2)
library(plyr)
library(dplyr)
library(reshape)
library(pROC)
library(dotwhisker)
library(broom)
library(MASS)
library(glmnet)
library(class)
library(caret)
library(ROCR)
library(tree)
library(rpart)
library(rpart.plot)
library(randomForest)
library(klaR)

##############
#            #
# Functions  #
#            #
##############

#Mahalanobis distance
mdist<-function(x) {
  t<-as.matrix(x) # transform x to a matrix
  m<-apply(t,2,mean) # compute column mean
  s<-var(t) # compute sample covariance matrix
  mahalanobis(t,m,s) # using built-in mahalanobis function
}

#Save plot to directory
save.plot <- function(plot, name="Rplot", dir=save.to.dir,type='png',
                      width = NULL, height = NULL) {
  dir.create(dir, showWarnings = F)
  if(name=="Rplot")
    warning("You are using the default filename, file overwriting is possible.
            Better name the file by yourself.")
  
  filedir = file.path(dir, paste(name, type, sep='.'))
  
  if (type == 'pdf') {
    if (is.null(width)) width = 7
    if (is.null(height)) height = 7
    pdf(filedir, width = width, height = height)
  }
  
  else {
    if (is.null(width)) width = 480
    if (is.null(height)) height = 480
    if (type=='png')
      png(filedir, width = width, height = height)
    else if (type == 'jpg' || type == 'jpeg')
      jpeg(filedir, width = width, height = height)
    else if (type == 'bmp')
      bmp(filedir, width = width, height = height)
    else
      warning("File type can only be 'png', 'pdf', 'jpg', 'jpeg', 'bmp'")
  }
  
  print(plot) #Note, in the function, you must explicitly print the plot
  dev.off()
}

#Data Standardization
std <- function(x,method='minmax') {
  xn = nrow(x)
  mat1 = rep(1,xn)
  if (method=='minmax') {
    xminmat = mat1%*%t(apply(x,2,min))
    xmaxmat = mat1%*%t(apply(x,2,max))
    xstand = (x-xminmat)/(xmaxmat-xminmat)
  }
  else if (method=='meansd') {
    xsdmat = mat1%*%t(sqrt(apply(x,2,var)))
    xmeanmat = mat1%*%t(apply(x,2,mean))
    xstand = (x-xmeanmat)/xsdmat
  }
  else
    return (x)
  xstand
}

#Calculate the area ratio of the lift chart (see the report for detail)
area_ratio <- function(pr,y){
  ysort<-y[order(pr,decreasing=T)]
  perc<-cumsum(ysort)/sum(ysort)
  pop<-(1:length(ysort))/length(ysort)
  perfect<-cumsum(sort(ysort,decreasing = TRUE))/sum(ysort)
  return((Area_Under_Curve(pop,perc)-0.5)/(Area_Under_Curve(pop,perfect)-0.5))
}

#Get the data frame of three cumsums for the lift chart 
#Parameters:
#pr: the vector of predicted probabilities
#y: the vector of actual categories (must be either 0 or 1)
get_lift_vec <- function(pr, y){
  if(length(pr) != length(y))
    stop('The two parameters must have the same length.')
  
  n <- length(pr) 
  n1 <- sum(y==1)
  n0 <- n - n1
  ysort <- y[order(pr,decreasing=T)]
  baseline <- (1:n)/n
  perfect <- cumsum(c(rep(1,n1),rep(0,n0)))/sum(y)
  model <- cumsum(ysort)/sum(y)
  return(data.frame(perfect, model, baseline))
}

#################
#               #
# Read in data  #
#               #
#################

d <- read.csv("credit.csv")
varnames.ini <- names(d)
nobs.ini <- nrow(d)
nY0.ini <- nrow(d[d$Y==0,]) #Y==1: positive. Y==0: negative
nY1.ini <- nrow(d[d$Y==1,])

#Correlation of predictors#
dnonf <- d[,-c(1,3,5)]
z <- cor(dnonf)     # obtain the correlation matrix
z.m <- melt(z)        # Cartesian product
cormatrix <- ggplot(z.m, aes(X1, X2, fill = value)) +
  geom_tile() + scale_fill_gradient2(low = "lightblue", mid = "white", high = "coral") +
  labs(x='Variables',y='Variables',title = 'Correlation heatmap')
ggsave(cormatrix, filename = "corrlation heatmap.png",  bg = "transparent", 
       path = save.to.dir)

#################
#               #
# Data cleaning #
#               #
#################

#######################################
# Step 1: Outlier elimination (mdist) #
#######################################

x <- subset(d, select = -c(ID,SEX,EDUCATION, MARRIAGE,Y)) # save d to x
md<-mdist(x) # compute mdist
mdx <- data.frame(index=1:length(md),md=md)
c<-qchisq(0.95,df=ncol(x)) # p=ncol(x), and type-I error = 0.01
mdist_before <- ggplot(mdx, aes(y = md, x = index)) + geom_point() + 
  geom_hline(yintercept = c, col='red')

dclean<-d[md<c,]
x2 <- x[md<c,]
#To show that the outlier elimination doesn't effect the data much
nY0 <- nrow(dclean[dclean$Y==0,])
nY1 <- nrow(dclean[dclean$Y==1,])
nobs <- nrow(dclean)
propY1.ini <- nY1.ini/nobs.ini
propY1 <- nY1/nobs

md2 <- mdist(x2)
mdx2 <- data.frame(index=1:length(md2),md=md2)
mdist_no_outlier <- ggplot(mdx2, aes(y = md, x = index)) + geom_point()

save.plot(mdist_before, 'mdist_before')
save.plot(mdist_no_outlier, 'mdist_no_outlier')

#####################################
#  Step 2: Varaible reduction (PCA) #
#####################################

d<-dclean

#######PCA BILL_AMT
BA<-d[,c("BILL_AMT1","BILL_AMT2","BILL_AMT3","BILL_AMT4",
         "BILL_AMT5","BILL_AMT6")]
pca<-princomp(BA,cor=T)  #perform pca using correlation matrix
s<-pca$sdev #save the s.d. of all PC to s
pca.var <- round(s^2,4)             #display variance
t<-sum(s^2)       #compute total variance
pca.prop <- round(s^2/t,4)    #proportion of variance explained by each PC
pca.cum <- cumsum(s^2/t)    ##cumulative sum of proportion of variance  

compvar <- melt(pca.prop)
compvar$index <- rownames(compvar)
pcaPercen <- ggplot(compvar,aes(x=index, y=value, group=1)) + 
  geom_point() + 
  geom_line() + 
  labs(x='',y='percentage', title='variance explained proportion')

save.plot(pcaPercen, 'pca-plot', width=800, height=400)

####we use the 1st PC to represent all the 6 variables
pcload <- as.data.frame(pca$loadings[,1:3]) #PC1 parallel shift, PC2 tilt, PC3 curvature
pcload$varnames=rownames(pcload)

pc1<-pcload[,1]*(-1)   ###since all the loadings are negative
BA<-as.matrix(BA)
BA<-BA %*% pc1
clean2 <- d
clean2[,c("BILL_AMT1")]<-BA
clean2<- subset(clean2,select=-c(BILL_AMT2,BILL_AMT3,
                                 BILL_AMT4,BILL_AMT5,BILL_AMT6))
names(clean2)[grep("BILL_AMT1",names(clean2))]<-"BILL_AMT"

################################
# Step 3: Data standardization #
################################

x <- subset(clean2,select=-c(ID))
xfac <- subset(x,select=c(SEX,EDUCATION, MARRIAGE))
x1 <- subset(x,select=6:11)
x2 <- subset(x,select=c(1,5,12:18))
xstand <- cbind(xfac,std(x1,method='minmax'),std(x2,method='meansd'),Y=x[,'Y'])
varnames.clean <- names(xstand)

#######################
#                     #
# penalized regression#
#                     #
#######################

set.seed(568)
##Cross Validation
d <- xstand
rownames(d) <- NULL
pred.m11<-c()
pred.l11<-c()
rate1<-c()
rate2<-c()
n=nrow(x)
predp.Ridge_min<-rep(NA,n)
predp.Ridge_1se<-rep(NA,n)
predp.Lasso_min<-rep(NA,n)
predp.Lasso_1se<-rep(NA,n)
predp.elstic_min<-rep(NA,n)
predp.elstic_1se<-rep(NA,n)
predp01.Ridge_min<-rep(NA,n)
predp01.Ridge_1se<-rep(NA,n)
predp01.Lasso_min<-rep(NA,n)
predp01.Lasso_1se<-rep(NA,n)
predp01.elstic_min<-rep(NA,n)
predp01.elstic_1se<-rep(NA,n)
predpmatrix<-matrix(0,ncol=6,nrow=10)
colnames(predpmatrix) <- c("ridge.min","ridge.1se","lasso.min","lasso.1se","elasticnet.min","elasticnet.1se")
x=model.matrix(Y~.,data=d)[,-c(1,19)]
y=d$Y
folds<-sample(cut(seq(1,nrow(d)),breaks = 10,labels = FALSE))
for(i in 1:10){ #loop for repeated cross-validation
  testIndexes<-which(folds==i,arr.ind=TRUE)
  testData<-d[testIndexes,] 
  trainData<-d[-testIndexes,]
  x.train<-x[-testIndexes,]
  y.train<-y[-testIndexes]
  x.test<-x[testIndexes,]
  y.test<-y[testIndexes]
  
  #ridge, lasso
  fit.ridge <- cv.glmnet(x.train, y.train, family="binomial", type.measure="class",alpha=0)
  rp1=predict(fit.ridge,newx=x.test,type="response",s=fit.ridge$lambda.min)
  pred.pr1=ifelse(rp1 <0.5, 0, 1)
  predp.Ridge_min[folds==i]<-as.numeric(rp1)
  predp01.Ridge_min[folds==i]<-as.numeric(pred.pr1)
  
  rp2=predict(fit.ridge,newx=x.test,type="response",s=fit.ridge$lambda.1se)
  pred.pr2=ifelse(rp2 <0.5, 0, 1)
  predp.Ridge_1se[folds==i]<-as.numeric(rp2)
  predp01.Ridge_1se[folds==i]<-as.numeric(pred.pr2)
  
  fitlas=cv.glmnet(x.train, y.train, type.measure="class", alpha=1,family="binomial")
  lap1=predict(fitlas,newx=x.test,type="response",s=fitlas$lambda.min)
  pred.lap1=ifelse(lap1 <0.5, 0, 1)
  predp.Lasso_min[folds==i]<-as.numeric(lap1)
  predp01.Lasso_min[folds==i]<-as.numeric(pred.lap1)
  
  lap2=predict(fitlas,newx=x.test,type="response",s=fitlas$lambda.1se)
  pred.lap2=ifelse(lap2 <0.5, 0, 1)
  predp.Lasso_1se[folds==i]<-as.numeric(lap2)
  predp01.Lasso_1se[folds==i]<-as.numeric(pred.lap2)
  
  assign(paste("fit_lasso",i,sep = ""), glmnet(x.train, y.train, alpha=1,family="binomial"))
  assign(paste("fit_ridge",i,sep = ""), glmnet(x.train, y.train, alpha=0,family="binomial"))
  
  #elstic net
  for (j in 1:9) {
    folds1<-sample(cut(seq(1,nrow(x.train)),breaks = 10,labels = FALSE))
    for(l in 1:10){
      testIndexes1<-which(folds1==l,arr.ind=TRUE)
      x.train1<-x.train[-testIndexes1,]
      x.test1<-x.train[testIndexes1,]
      y.train1<-y.train[-testIndexes1]
      y.test1<-y.train[testIndexes1]
      fit=cv.glmnet(x.train1, y.train1, type.measure="class", alpha=j/10,family="binomial")
      pred.m1 = ifelse(predict(fit,newx=x.test1,s=fit$lambda.min,type="class") == y.test1, 0,1)
      pred.m11[l]=sum(pred.m1)
      pred.l1 = ifelse(predict(fit,newx=x.test1,s=fit$lambda.1se,type="class") == y.test1, 0,1)
      pred.l11[l]=sum(pred.l1)
    }
    rate1[j]=sum(pred.m11)/nrow(x.train)
    rate2[j]=sum(pred.l11)/nrow(x.train)
  }
  alp1=which.min(rate1)
  alp2=which.min(rate2)
  gl1=cv.glmnet(x.train, y.train, type.measure="class", alpha=alp1/10,family="binomial")
  gp1=predict(gl1,newx=x.test,type="response",s=gl1$lambda.min)
  pred.gp1=ifelse(gp1 <0.5, 0, 1)
  predp.elstic_min[folds==i]<-as.numeric(gp1)
  predp01.elstic_min[folds==i]<-as.numeric(pred.gp1)
  
  gl2=cv.glmnet(x.train, y.train, type.measure="class", alpha=alp2/10,family="binomial")
  gp2=predict(gl2,newx=x.test,type="response",s=gl2$lambda.1se)
  pred.gp2=ifelse(gp2 <0.5, 0, 1)
  predp.elstic_1se[folds==i]<-as.numeric(gp2)
  predp01.elstic_1se[folds==i]<-as.numeric(pred.gp2)
}

#coef boxplot
fitlassocoef<-matrix(NA,ncol=17,nrow=10)
colnames(fitlassocoef)<-c("sex","education","marriage","pay0","pay2","pay3","pay4","pay5","pay6","lim","age","bill","payamt1","payamt2","payamt3","payamt4","payamt5" )
for(i in 1:10){
  vcoef<-coef(get(paste("fit_lasso",i,sep = "")))
  fitlassocoef[i,]=vcoef[-1,ncol(vcoef)]
}
boxplot(fitlassocoef,main="Coefficient of each Variable for Lasso")
abline(h=0,col="red")

predpmatrix[i,1]=sum(ifelse(predp01.Ridge_min==y,0,1))
predpmatrix[i,2]=sum(ifelse(predp01.Ridge_1se==y,0,1))
predpmatrix[i,3]=sum(ifelse(predp01.Lasso_min==y,0,1))
predpmatrix[i,4]=sum(ifelse(predp01.Lasso_1se==y,0,1))
predpmatrix[i,5]=sum(ifelse(predp01.elstic_min==y,0,1))
predpmatrix[i,6]=sum(ifelse(predp01.elstic_1se==y,0,1))
colSums(predpmatrix)/nrow(x)

predmaxmatrix<-matrix(0,ncol=6,nrow=2)
rownames(predmaxmatrix) <-c("cut-off","Accuracy")
colnames(predmaxmatrix) <- c("ridge.min","ridge.1se","lasso.min","lasso.1se","elsticnet.min","elsticnet.1se")

#plot ROC
roc1<-roc(y,predp.Ridge_min, direction="<")
roc2<-roc(y, predp.Ridge_1se, direction="<")
roc3<-roc(y,predp.Lasso_min, direction="<")
roc4<-roc(y, predp.Lasso_1se, direction="<")
roc5<-roc(y,predp.elstic_min, direction="<")
roc6<-roc(y, predp.elstic_1se, direction="<")

gg<-ggroc(list(Ridge.min=roc1, Ridge.1se=roc2,Lasso.min=roc3,Lasso.1se=roc4,Elasticnet.min=roc5,Elasticnet.1se=roc6), aes="colour",lwd=0.5,lty=1)
g <- gg + theme(legend.title=element_blank())+ ggtitle("ROC for Penalized Models")
ggsave(g, filename = "ROC for Penalized Models.png", path = save.to.dir)

auc(roc1)
auc(roc2)
auc(roc3)
auc(roc4)
auc(roc5)
auc(roc6)

P<-sum(y)
N<-length(y)-P
acura1<-(roc1$sensitivities*P+roc1$specificities*N)/(P+N)
cutoff1<-roc1$thresholds[which.max(acura1)]
predmaxmatrix[1,1]=cutoff1
predmaxmatrix[2,1]=max(acura1)

acura2<-(roc2$sensitivities*P+roc2$specificities*N)/(P+N)
cutoff2<-roc2$thresholds[which.max(acura2)]
predmaxmatrix[1,2]=cutoff2
predmaxmatrix[2,2]=max(acura2)

acura3<-(roc3$sensitivities*P+roc3$specificities*N)/(P+N)
cutoff3<-roc3$thresholds[which.max(acura3)]
predmaxmatrix[1,3]=cutoff3
predmaxmatrix[2,3]=max(acura3)

acura4<-(roc4$sensitivities*P+roc4$specificities*N)/(P+N)
cutoff4<-roc4$thresholds[which.max(acura4)]
predmaxmatrix[1,4]=cutoff4
predmaxmatrix[2,4]=max(acura4)

acura5<-(roc5$sensitivities*P+roc5$specificities*N)/(P+N)
cutoff5<-roc5$thresholds[which.max(acura5)]
predmaxmatrix[1,5]=cutoff5
predmaxmatrix[2,5]=max(acura5)

acura6<-(roc2$sensitivities*P+roc6$specificities*N)/(P+N)
cutoff6<-roc2$thresholds[which.max(acura6)]
predmaxmatrix[1,6]=cutoff6
predmaxmatrix[2,6]=max(acura6)

#Lift Chart
Ridge.min_result=get_lift_vec(predp.Ridge_min,y)
roc.ridge_min <- data.frame(pop=Ridge.min_result$baseline,Ridge.min_result)

Ridge.1se_result=get_lift_vec(predp.Ridge_1se,y)
roc.ridge_1se <- data.frame(pop=Ridge.1se_result$baseline,Ridge.1se_result)

Lasso.min_result=get_lift_vec(predp.Lasso_min,y)
roc.lasso_min <- data.frame(pop=Lasso.min_result$baseline,Lasso.min_result)

Lasso.1se_result=get_lift_vec(predp.Lasso_1se,y)
roc.lasso_1se <- data.frame(pop=Lasso.1se_result$baseline,Lasso.1se_result)

Elstic.min_result=get_lift_vec(predp.elstic_min,y)
roc.elstic_min <- data.frame(pop=Elstic.min_result$baseline,Elstic.min_result)

Elstic.1se_result=get_lift_vec(predp.elstic_1se,y)
roc.elstic_1se <- data.frame(pop=Elstic.1se_result$baseline,Elstic.1se_result)

cn<-cbind(roc.ridge_min[,1:3],roc.ridge_1se[,3],roc.lasso_min[,3],roc.lasso_1se[,3],roc.elstic_min[,3],roc.elstic_1se[,3],roc.ridge_min[,4])
colnames(cn)<-c("pop","Perfect","Ridge.min","Ridge.1se","Lasso.min","Lasso.1se","Elasticnet.min","Elasticnet.1se","Baseline")
lcr1 <- melt(cn,id.vars='pop')
pl.r2 <- ggplot(lcr1, aes(x = pop, y=value, color=variable)) + geom_line(size=0.5) + scale_color_manual(values=c("#66ccff","#0000ff", "#ff0000","#333333","#e69f00","#458b00","#8064a2","#66ccff"))
lcrm.lift2 <- pl.r2 +  labs(x="",y="Cumulative Percentage") + theme(legend.title=element_blank())+ ggtitle("Lift Chart for Penalized Models")

area_ratio(predp.Ridge_min,y)
area_ratio(predp.Ridge_1se,y)

area_ratio(predp.Lasso_min,y)
area_ratio(predp.Lasso_1se,y)

area_ratio(predp.elstic_min,y)
area_ratio(predp.elstic_1se,y)

#######################
#                     #
# logistic regression #
#                     #
#######################
set.seed(568)
dlreg <- xstand
dlreg[,c(1,3)] <- lapply(dlreg[,c(1,3)],factor)

set.seed(12345) # set random seed

lreg<-glm(Y~. ,data=dlreg, binomial)
lreg<-step(lreg) # AIC stepwise

coef.lreg <- dwplot(lreg) + xlab("Coefficient Estimate") + ylab("") +
  ggtitle("Coefficient for Logistice regression") #plot logistic regression coefficient
ggsave(coef.lreg, filename = "Logistic Coefficient.png", path = save.to.dir)

k<-10 #10-fold cross validation
block <- sample(c(rep(1:9, 2671), rep(10, 2677)))
predLreg <- NULL
for(i in 1:k) {
  # fit logistic models to all but i-th block
  train <- glm(formula = lreg$formula, family = binomial, 
                  data = dlreg[block != i, ])
  # predicted prob(Y=1) for i-th block
  predLreg[block == i] <- predict(train, newdata = dlreg[block == i, ], 
            type = "response")
}
predLregClass <- (as.numeric(predLreg > 0.5) + 1)

#Error table
lreg.table <- table(as.numeric(predLregClass),dlreg$Y)
lreg.error <- (lreg.table[2]+lreg.table[3])/sum(lreg.table)

#roc
roc.lreg <- roc(dlreg$Y, predLreg, direction = "<")
lreg_ROC<-ggroc(list(Logistic.Regression=roc.lreg), aes="colour",lwd=0.5,lty=1)
lreg_ROC <- lreg_ROC + theme(legend.title=element_blank())+ ggtitle("ROC for Logistic Regression")
ggsave(lreg_ROC, filename = "ROC for Logistic Regression.png", path = save.to.dir)

#accuracy rate
ar.lreg <- (roc.lreg$sensitivities * sum(dlreg$Y) + roc.lreg$specificities * sum(dlreg$Y == 0)) / nrow(dlreg)
cutoff.lreg <- roc.lreg$thresholds[which.max(ar.lreg)]
cutoff.lreg
max(ar.lreg)

#lift chart
lreg_lift_vec <- get_lift_vec(predLreg, dlreg$Y)
                                                                     
#plot
lreg_lift_vec <- data.frame(pop = lreg_lift_vec$baseline,lreg_lift_vec)
lreg_lift_vec <- melt(lreg_lift_vec, id.vars='pop')
lreg_LiftChart <- ggplot(lreg_lift_vec, aes(x = pop, y=value, color=variable)) + 
  geom_line(size=1) + scale_color_manual(values=c("#66CCFF","#003399", "#66CCFF"))
lreg_LiftChart <- lreg_LiftChart +  labs(x="",y="Cumulative Percentage",title="Lift Chart for logistic regression") +
  theme(legend.title=element_blank()) + ggtitle("Lift Chart for Logistic regression")
save.plot(lreg_LiftChart, name='lreg_LiftChart', width = 800, height=480)

#AR
area_ratio_lreg <- area_ratio(predLreg, dlreg$Y)
area_ratio_lreg
#####################################################################

###################
#                 #
# Machine Leaning #
#                 #
###################
creditcard=xstand
creditcard$SEX=as.factor(creditcard$SEX)
creditcard$EDUCATION=as.factor(creditcard$EDUCATION)
creditcard$MARRIAGE=as.factor(creditcard$MARRIAGE)
creditcard$Y=as.factor(creditcard$Y)
summary(creditcard)
attach(creditcard)
library(caret)
set.seed(568)
train_size=0.7
train_index = createDataPartition(creditcard$Y,p = train_size, list = FALSE,times = 1)
train_set=creditcard[train_index,]
test_set=creditcard[-train_index,]

################################
#            KNN               #
################################
# Select k applying cross-validation
knn_acc=rep(NA,100)
for (i in 1:100){
  knn_data=creditcard[,-19]
  knn_default=creditcard[,19]
  results=knn.cv(knn_data,knn_default,1:length(knn_default),k=i)
  print(i)
  knn_acc[i]=(table(results,knn_default)[1,1]+table(results,knn_default)[2,2])/(sum(table(results,knn_default)))
}

which.max(knn_acc)
plot(knn_acc,xlab="Number of nearest neighbours",ylab="Accuracy",type='l',main="Highest Accuracy: 0.793,   K=16",lwd=3)
points(16,knn_acc[16],col="red",cex=2,pch=20)

# When k=16, we obtained the highest accracy.

model_knn = knn(train = train_set[, -19],test = test_set[, -19],cl = train_set[, 19],k = 16,prob = TRUE)
model_knn_table = table(test_set[, 19], model_knn)
confusionMatrix(model_knn_table)
model_knn=as.numeric(model_knn)
pred = prediction(model_knn, test_set$Y)
perf_knn = performance(pred, measure = "tpr", x.measure = "fpr") 
auc = performance(pred, measure = "auc")
auc = auc@y.values[[1]]
auc

################################
#            Tree Modeling     #
################################
set.seed(568)
tree.credit=tree(Y~.,data=creditcard)
summary(tree.credit)
# "Decision Tree Before Pruning"
plot(tree.credit)
text(tree.credit,pretty=0)
model_tree=rpart(Y~.,data=creditcard,method="class")
print(model_tree)
summary(model_tree)
model.pruned=prune(model_tree,cp=0.01)
# Next, we prune the tree 
prp(model.pruned, type = 2, extra = 104,
    fallen.leaves = TRUE, main="Decision Tree After Pruning")
model_tree_pred = predict(model.pruned, test_set, type="class")

################################
#            Random Forest     #
################################
rf.prelim=randomForest(Y~.,data=creditcard,importance=TRUE)
varImpPlot(rf.prelim)
importance(rf.prelim)
train.x=train_set[,1:18]
train.y=train_set[,19]
levels(train_set$Y)=list("Yes"=1,"No"=0)
control = trainControl(method="cv", number=10,classProbs = TRUE, summaryFunction = twoClassSummary)
metric = "ROC"
mtry=sqrt(ncol(train.x))
tunegrid = expand.grid(.mtry=c(mtry,5))
rf_default = train(Y~., data=train_set, method="rf", metric=metric, tuneGrid=tunegrid, trControl=control)
print(rf_default)
myroc = pROC::roc(test_set$Y, as.vector(predRoc[,2]))
plot(myroc, print.thres = "best",print.thres.best.method="closest.topleft",main="AUC= 0.77, Accuracy=0.79")
library(pROC)
threshold = coords(myroc,x="best",best.method = "closest.topleft")[[1]] #get optimal cutoff threshold
threshold

predRoc = predict(rf_default, test_set, type = "prob")

get_ROC_vec <- function(pr, y){
  if(length(pr) != length(y))
    stop('The two parameters must have the same length.')
  n <- length(pr) 
  n1 <- sum(y==1)
  n0 <- n - n1
  ysort <- y[order(pr,decreasing=T)]
  baseline <- (1:n)/n
  perfect <- cumsum(c(rep(1,n1),rep(0,n0)))/sum(y)
  model <- cumsum(ysort)/sum(y)
  return(data.frame(perfect, model, baseline))
}

levels(creditcard$Y)=list("Yes"=1,"No"=0)
rf_default = train(Y~., data=train_set, method="rf", metric=metric, tuneGrid=tunegrid, trControl=control)

predRoc = predict(rf_default, test_set, type = "prob")
predRoc1=predRoc[,1]
library(reshape)
library(MLmetrics)
test_set$Y=as.numeric(test_set$Y)
test_set$Y=test_set$Y-1
RFresult=get_ROC_vec(predRoc1,test_set$Y)
RF<- data.frame(pop=RFresult$baseline,RFresult)
colnames(RF)<-c("pop","Perfect","Random Forest","Baseline")
rf1 <- melt(RF,id.vars='pop')
pl.rf <- ggplot(rf1, aes(x = pop, y=value, color=variable)) + geom_line(size=1) + scale_color_manual(values=c("#66ccff","#cc6600", "#66ccff"))
lift <- pl.rf +  labs(x="",y="Cumulative Percentage") + theme(legend.title=element_blank())+ ggtitle("Lift chart for Random Forest")
lift

accuracy_ratio <- function(pr,y){
  ysort<-y[order(pr,decreasing=T)]
  perc<-cumsum(ysort)/sum(ysort)
  pop<-(1:length(ysort))/length(ysort)
  perfect<-cumsum(sort(ysort,decreasing = TRUE))/sum(ysort)
  return((Area_Under_Curve(pop,perc)-0.5)/(Area_Under_Curve(pop,perfect)-0.5))
}

accuracy_ratio(predRoc1,test_set$Y)

################################
#Linear Discriminant Analysis  #
################################
set.seed(568)
vlda = function(v,formula,data,cl){
  require(MASS)
  grps = cut(1:nrow(data),v,labels=FALSE)[sample(1:nrow(data))]
  lda_pred = lapply(1:v,function(i,formula,data){
    omit = which(grps == i)
    z = lda(formula,data=data[-omit,])
    predict(z,data[omit,])
  },formula,data)
  
  wh = unlist(lapply(lda_pred,function(pp)pp$class))
  table(wh,cl[order(grps)])
  
}

model_lda = vlda(10,Y~.,creditcard,creditcard$Y) 
LDA_ac=(model_lda[1,1]+model_lda[2,2])/sum(model_lda)
lda.fit = lda(Y ~., train_set)
lda.pred=predict(lda.fit,test_set)
pred = prediction(lda.pred$posterior[,2], test_set$Y) 
perf_lda = performance(pred,"tpr","fpr")
auc_lda=performance(pred,measure = "auc")
auc_lda = auc_lda@y.values[[1]]

################################
# Naive Bayes                  #
################################
test.x=test_set[,1:18]
test.y=test_set[,19]
model = train(train.x,train.y,'nb',trControl=trainControl(method='cv',number=10))
tt_nb=table(predict(model$finalModel,test.x)$class,test.y)
(NB_ac_cross_sen = (tt_nb[1,1]+tt_nb[2,2]) / sum(tt_nb))
levels(train_set$Y)=list("Yes"=1,"No"=0)
nb_mod = train(x = train_set[, 1:18], y = train_set[, 19], 
               method = "nb", trControl = trainControl(method = "cv", classProbs = TRUE))
nb_pred=predict(nb_mod, newdata = test_set[ , 1:18], type = "prob")
pred = prediction(nb_pred[, "Yes"], test_set$Y)
perf_nb = performance(pred, measure='tpr', x.measure='fpr')
auc = performance(pred, measure = "auc")
auc = auc@y.values[[1]]
auc
plot(perf_nb, main="Naive Bayes")
roc.data = data.frame(fpr=unlist(perf_nb@x.values),
                      tpr=unlist(perf_nb@y.values),
                      model="GLM")
ggplot(roc.data, aes(x=fpr, ymin=0, ymax=tpr)) +
  geom_ribbon(alpha=0.2) +
  geom_line(aes(y=tpr)) +
  ggtitle(paste0("ROC Curve with AUC=", round(auc,3)))+xlab("False Positive Rate")+ylab("True Positive Rate")+theme_bw()+geom_segment(aes(x = 0, xend = 1, y = 0, yend = 1),color="blue",linetype="dashed")+xlim(0,1)

################################
#            Comparison        #
################################

plot(perf_lda, main = "ROC for LDA (0.73) and Naive Bayes (0.75)", col='blue',lwd=3)
abline(0,1,lty=2,lwd=2)
plot(perf_nb, add=TRUE, col='red',lwd=3)
legend('right', c("Naive Bayes", "LDA"), fill = c('red','blue'), bty='n')

